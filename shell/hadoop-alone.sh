#!/usr/bin/bash
#
# é—®é¢˜1ï¼šJDKç¯å¢ƒæ˜¯å¦å­˜åœ¨çš„åˆ¤æ–­æœ‰é—®é¢˜
# é—®é¢˜2ï¼šå¯åŠ¨hadoopå°‘ä¸€ä¸ªresourceManager
#
echo "æ£€æŸ¥æ˜¯å¦å­˜åœ¨yumå·¥å…·..."
yum_result=$(yum --version)
if [ $? -ne 0 ]; then
	echo "ä¸å­˜åœ¨yumå·¥å…·ï¼Œå¼€å§‹å®‰è£…yum..."
fi
expect=$(expect -v)
if [ $? -ne 0 ]; then
	echo "ä¸å­˜åœ¨expectå·¥å…·ï¼Œå¼€å§‹å®‰è£…expect..."
	$(yum install -y expect)
fi
echo "æ£€æŸ¥æ˜¯å¦å­˜åœ¨JDKç¯å¢ƒ..."
if [ -z $(echo $JAVA_HOME) ]; then
	echo "åˆ é™¤opensshè‡ªå¸¦çš„JDK..."
	for every in $(rpm -qa | grep jdk); do
		rpm -e --nodeps $every
	done
	echo "ä¸‹è½½jdk8..."
	#cd /tmp && wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" https://repo.huaweicloud.com/java/jdk/8u151-b12/jdk-8u151-linux-x64.rpm
	chmod +x /tmp/jdk-8u151-linux-x64.rpm && rpm -ivh /tmp/jdk-8u151-linux-x64.rpm
	echo "é…ç½®JDKç¯å¢ƒå˜é‡..."
	sed -i '$aexport JAVA_HOME=/usr/java/jdk1.8.0_151' /etc/profile
	sed -i '$aexport PATH=$JAVA_HOME/bin:$PATH' /etc/profile
	source /etc/profile
	test_result=$(java -version)
	if [ $? -eq 0 ]; then
		echo "jdkå®‰è£…æˆåŠŸï¼"
		#rm -rf /tmp/jdk-8u151-linux-x64.rpm
	else
		echo "ERRORï¼jdkå®‰è£…å¤±è´¥ï¼"
		exit
	fi
else
	echo "å­˜åœ¨JDKç¯å¢ƒ!"
fi
echo "æ£€æŸ¥æ˜¯å¦å­˜åœ¨hadoopç¯å¢ƒ..."
hadoop version
if [ $? -ne 0 ]; then
	echo "ä¸å­˜åœ¨hadoopç¯å¢ƒï¼Œä¸‹è½½hadoopå®‰è£…åŒ…..."
	#cd /tmp && wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz
	if [ ! -d /opt/module ]; then
		mkdir -p /opt/module
	fi
	cd /tmp && tar -zxvf hadoop-3.2.3.tar.gz -C /opt/module
	if [ -n "$(ls /opt/module | grep hadoop-3.2.3)" ]; then
		echo "è§£å‹æˆåŠŸ!"
		cd /opt/module && chown -R root:root hadoop-3.2.3 && chmod -R 777 hadoop-3.2.3
	else
		echo "ERRORï¼è§£å‹å¤±è´¥ï¼"
    		exit
	fi
	JAVA_HOME=$(echo $JAVA_HOME)
	echo "é…ç½®hadoopç¯å¢ƒå˜é‡..."
	sed -i '$aexport HADOOP_HOME=/opt/module/hadoop-3.2.3' /etc/profile
	sed -i '$aexport PATH=$HADOOP_HOME/bin:$PATH' /etc/profile
	sed -i '$aexport PATH=$HADOOP_HOME/sbin:$PATH' /etc/profile
	sed -i '$aexport HDFS_NAMENODE_USER=root' /etc/profile
	sed -i '$aexport HDFS_DATANODE_USER=root' /etc/profile
	sed -i '$aexport HDFS_SECONDARYNAMENODE_USER=root' /etc/profile
  	sed -i '$aexport YARN_RESOURCEMANAGER_USER=root' /etc/profile
  	sed -i '$aexport YARN_NODEMANAGER_USER=root' /etc/profile
  	source /etc/profile
  	sed -i '$aexport JAVA_HOME=/usr/java/jdk1.8.0_151' /opt/module/hadoop-3.2.3/etc/hadoop/hadoop-env.sh
  	test_result=$(hadoop version)
  	if [ $? -eq 0 ]; then
    		echo "Hadoopå®‰è£…æˆåŠŸï¼"
    		#rm -rf /tmp/hadoop-3.2.3.tar.gz
  	else
    		echo "ERRORï¼Hadoopå®‰è£…å¤±è´¥ï¼"
    		exit
	fi
	export JAVA_HOME=$JAVA_HOME
	export HADOOP_HOME=/opt/module/hadoop-3.2.3
	export PATH=$HADOOP_HOME/bin:$PATH
	export PATH=$HADOOP_HOME/sbin:$PATH
	export HDFS_NAMENODE_USER=root
	export HDFS_DATANODE_USER=root
	export HDFS_SECONDARYNAMENODE_USER=root
	export YARN_RESOURCEMANAGER_USER=root
	export YARN_NODEMANAGER_USER=root

	echo "å…³é—­é˜²ç«å¢™..."
	$(systemctl stop firewalld)
	echo "è‡ªåŠ¨é…ç½®hadoopçš„è‡ªå®šä¹‰é…ç½®..."
	sed -i '19a<property><name>fs.defaultFS</name><value>hdfs://0.0.0.0:8020</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/core-site.xml
	sed -i '20a<property><name>hadoop.tmp.dir</name><value>/opt/module/hadoop-3.2.3/data</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/core-site.xml
	sed -i '21a<property><name>hadoop.http.staticuser.user</name><value>root</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/core-site.xml
	sed -i '22a<property><name>hadoop.proxyuser.root.hosts</name><value>*</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/core-site.xml
	sed -i '23a<property><name>hadoop.proxyuser.root.groups</name><value>*</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/core-site.xml
	sed -i '19a<property><name>dfs.namenode.http-address</name><value>0.0.0.0:9870</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/hdfs-site.xml
	sed -i '20a<property><name>dfs.namenode.secondary.http-address</name><value>0.0.0.0:9868</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/hdfs-site.xml
	sed -i '15a<property><name>yarn.nodemanager.aux-services</name><value>mapreduce_shuffle</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/yarn-site.xml
	sed -i '16a<property><name>yarn.resourcemanager.hostname</name><value>localhost</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/yarn-site.xml
	sed -i '17a<property><name>yarn.resourcemanager.webapp.address</name><value>localhost:8088</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/yarn-site.xml
	sed -i '19a<property><name>mapreduce.framework.name</name><value>yarn</value></property>' /opt/module/hadoop-3.2.3/etc/hadoop/mapred-site.xml

	echo "é…ç½®å…å¯†ç™»å½•..."
	if [ -z "$(ls ~/.ssh | grep id_rsa.pub)" ]; then
		expect <<EOF
		spawn ssh-keygen -t rsa
		expect {
			"id_rsa):" { send "\n";exp_continue }
			"passphrase):" { send "\n";exp_continue }
			"again:" { send "\n";exp_continue }
		}
EOF
	cat ~/.ssh/id_rsa.pub >~/.ssh/authorized_keys
	fi
	echo "hdfsåˆå§‹åŒ–..."
	result=$(hdfs namenode -format)
	echo "å¼€å§‹å¯åŠ¨hadoopå„é¡¹æœåŠ¡..."
	source /etc/profile && source ~/.bash_profile && /opt/module/hadoop-3.2.3/sbin/start-all.sh
	cat <<EOF
      +---------------------------------------------------------------+
      |    Web ç«¯æŸ¥çœ‹ HDFS çš„ NameNodeï¼šhttp://0.0.0.0:9870            |
      |    Web ç«¯æŸ¥çœ‹ YARN çš„ ResourceManagerï¼šhttp://0.0.0.0:8088     |
      +---------------------------------------------------------------+
EOF
	echo "###Over###" # è‡ªå®šä¹‰ç»“æŸæ ‡å¿—
else
	echo "Hadoopç¯å¢ƒå·²å­˜åœ¨ï¼"
fi
echo "í ½í²•í ½í²•í ½í²•í ½í²•í ½í²•ä¸€å¥—æ“ä½œè¡Œäº‘æµæ°´í ½í²•í ½í²•í ½í²•í ½í²•í ½í²•"

